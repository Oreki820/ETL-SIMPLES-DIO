# ğŸš€ Pipeline ETL com Python e Regras Inteligentes de RecomendaÃ§Ã£o

Este projeto foi desenvolvido como parte do desafio da DIO no lab **"Explorando IA Generativa em um Pipeline de ETL"**, mas com uma adaptaÃ§Ã£o importante: em vez de usar uma API externa ou modelos de IA generativa, optei por criar um pipeline totalmente **local**, utilizando **Python**, **Pandas** e **lÃ³gica prÃ³pria de recomendaÃ§Ã£o**.

O objetivo foi manter a essÃªncia do ETL â€” **Extrair, Transformar e Carregar** â€” criando algo simples, eficiente e aplicÃ¡vel em vÃ¡rios cenÃ¡rios reais.

---

## ğŸ§  VisÃ£o Geral do Projeto

### âœ” **Extract (ExtraÃ§Ã£o)**

Para a etapa de extraÃ§Ã£o, gerei um conjunto de dados diretamente no prÃ³prio notebook, simulando uma pequena base de usuÃ¡rios contendo:

* nome
* interesse de estudo
* nÃ­vel de conhecimento

Essa abordagem permite reproduzir facilmente o processo sem depender de arquivos externos ou APIs.

---

### âœ” **Transform (TransformaÃ§Ã£o com Regras Customizadas)**

A etapa de transformaÃ§Ã£o foi totalmente personalizada.
Criei um sistema de recomendaÃ§Ãµes que analisa o interesse e o nÃ­vel de conhecimento do usuÃ¡rio para gerar automaticamente uma sugestÃ£o de curso adequada.

Exemplos:

* UsuÃ¡rios iniciantes recebem recomendaÃ§Ãµes introdutÃ³rias.
* UsuÃ¡rios intermediÃ¡rios recebem recomendaÃ§Ãµes prÃ¡ticas.
* UsuÃ¡rios avanÃ§ados recebem recomendaÃ§Ãµes de especializaÃ§Ã£o.

Esse tipo de lÃ³gica Ã© muito usado em pipelines reais, onde regras de negÃ³cio substituem modelos de IA quando o objetivo Ã© simplicidade, velocidade ou independÃªncia de serviÃ§os externos.

---

### âœ” **Load (Carregamento dos Dados Transformados)**

ApÃ³s gerar as recomendaÃ§Ãµes, os dados transformados sÃ£o carregados novamente em novos formatos que podem ser facilmente reutilizados em outros sistemas, anÃ¡lises ou integraÃ§Ãµes.

O carregamento demonstra como dados processados podem retornar para o fluxo de trabalho de forma organizada e estruturada.

---

## ğŸ¯ Objetivo do Projeto

O objetivo principal foi mostrar que Ã© possÃ­vel construir um pipeline ETL completo, robusto e Ãºtil mesmo sem depender de IA ou APIs externas.
A ideia central do desafio â€” pensar como um cientista de dados e criar um fluxo de dados funcional â€” foi totalmente preservada.

---

## ğŸ›  Tecnologias e Conceitos Aplicados

* Python
* Pandas
* ETL (Extract, Transform, Load)
* Regras de NegÃ³cio
* AutomaÃ§Ã£o de RecomendaÃ§Ãµes
* DataFrames
* ExportaÃ§Ã£o de dados

---

## ğŸ’¡ PossÃ­veis ExtensÃµes Futuras

* Adicionar anÃ¡lise estatÃ­stica dos usuÃ¡rios
* Gerar grÃ¡ficos de interesse por Ã¡rea
* Criar novas regras de recomendaÃ§Ã£o por perfil
* Integrar com API prÃ³pria usando FastAPI
* Criar um dashboard em Streamlit
* Aumentar o dataset com mais usuÃ¡rios e atributos
* Adicionar sistema de pontuaÃ§Ã£o e priorizaÃ§Ã£o

---

## ğŸ§‘â€ğŸ’» Autor

**Lucas Gabriel (Oreki)**
Cientista de Dados Jr
Apaixonado por dados, automaÃ§Ã£o e soluÃ§Ãµes inteligentes ğŸ’™
